Classification with framework
------------------------------
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)
y = np.array([0, 1, 1, 0], dtype=np.float32)

model = Sequential([
    Dense(4, activation='relu', input_shape=(2,)),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer=Adam(learning_rate=0.1),
              loss='binary_crossentropy',
              metrics=['accuracy'])

print("Training progress:")

history = model.fit(X, y, epochs=1000, verbose=0)

for i in range(0, 1000, 100):
    loss, acc = history.history['loss'][i], history.history['accuracy'][i]
    print(f"Epoch {i}: loss = {loss:.4f}, accuracy = {acc:.4f}")

predictions = model.predict(X)
predicted_classes = (predictions > 0.5).astype(int)

print("\nFinal Predictions:")
for i in range(len(X)):
    print(f"Input: {X[i]}, Predicted: {predicted_classes[i][0]} "
          f"(prob: {predictions[i][0]:.4f}), Actual: {y[i]}")

print("\nModel architecture:")
model.summary()
-------------------------------------------------------------------------------
Classification without framework
---------------------------------
import numpy as np

class NeuralNetwork:
    def __init__(self, input_size, hidden_size, output_size):
        np.random.seed(42) 
        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2. / input_size)
        self.b1 = np.zeros((1, hidden_size))
        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2. / hidden_size)
        self.b2 = np.zeros((1, output_size))

    def sigmoid(self, z):
        return 1 / (1 + np.exp(-z))

    def forward(self, X):
        self.z1 = np.dot(X, self.W1) + self.b1
        self.a1 = np.maximum(0, self.z1) 

        self.z2 = np.dot(self.a1, self.W2) + self.b2
        self.a2 = self.sigmoid(self.z2)
        return self.a2

    def backward(self, X, y, lr=0.1):
        m = X.shape[0]
        dz2 = self.a2 - y.reshape(-1, 1)
        dW2 = np.dot(self.a1.T, dz2) / m
        db2 = np.sum(dz2, axis=0, keepdims=True) / m
        dz1 = np.dot(dz2, self.W2.T) * (self.z1 > 0)
        dW1 = np.dot(X.T, dz1) / m
        db1 = np.sum(dz1, axis=0, keepdims=True) / m

        self.W1 -= lr * dW1
        self.b1 -= lr * db1
        self.W2 -= lr * dW2
        self.b2 -= lr * db2

    def train(self, X, y, epochs=1000, lr=0.1):
        for epoch in range(epochs):
            self.forward(X)
            self.backward(X, y, lr)

            if epoch % 100 == 0:
                loss = -np.mean(
                    y * np.log(self.a2 + 1e-8) + (1 - y) * np.log(1 - self.a2 + 1e-8)
                )
                print(f"Epoch {epoch}, Loss: {loss:.4f}")

    def predict(self, X, threshold=0.5):
        proba = self.forward(X)
        return (proba >= threshold).astype(int)


X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([0, 1, 1, 0])

nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1)
nn.train(X, y, epochs=1000, lr=0.1)

predictions = nn.predict(X)
print("\nFinal Predictions:")
for i in range(len(X)):
    print(f"Input: {X[i]}, Predicted: {predictions[i][0]}, Actual: {y[i]}")
---------------------------------------------------------------------------------------------
Image classification - Own dataset
------------------------------------
import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.losses import SparseCategoricalCrossentropy
import matplotlib.pyplot as plt
import kagglehub

path = kagglehub.dataset_download("samuelcortinhas/cats-and-dogs-image-classification")
print("Path to dataset files:", path)

img_height, img_width = 128, 128   
batch_size = 32

train_dataset = image_dataset_from_directory(
    f'{path}/train',
    image_size=(img_height, img_width),
    batch_size=batch_size,
    label_mode='int'
)

test_dataset = image_dataset_from_directory(
    f'{path}/test',
    image_size=(img_height, img_width),
    batch_size=batch_size,
    label_mode='int'
)

def normalize(images, labels):
    return tf.cast(images, tf.float32) / 255.0, labels

train_dataset = train_dataset.map(normalize)
test_dataset = test_dataset.map(normalize)

train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
test_dataset = test_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)

class_names = ["cat", "dog"]
num_classes = len(class_names)

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(img_height, img_width, 3)),
    MaxPooling2D(2,2),
    
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes)  
])

model.compile(
    optimizer='adam',
    loss=SparseCategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)

history = model.fit(
    train_dataset,
    epochs=10,
    validation_data=test_dataset
)

test_loss, test_acc = model.evaluate(test_dataset)
print(f"Test accuracy: {test_acc:.2f}")

probability_model = Sequential([model, tf.keras.layers.Softmax()])

for images, labels in test_dataset.take(1):
    predictions = probability_model.predict(images)
    plt.figure(figsize=(12, 3))
    for i in range(5):
        plt.subplot(1, 5, i+1)
        plt.imshow(images[i].numpy())  
        pred_label = class_names[tf.argmax(predictions[i])]
        true_label = class_names[labels[i]]
        color = 'green' if pred_label == true_label else 'red'
        plt.title(pred_label, color=color)
        plt.axis('off')
    plt.show()
